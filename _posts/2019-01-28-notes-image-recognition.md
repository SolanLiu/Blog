---
layout: post
#标题配置
title:  Image Recognition
#时间配置
date:   2019-01-28 01:08:00 +0800
#大类配置
categories: notes
#小类配置
tag: Image Algorithm
---

* content
{:toc}



# 图像分割

&emsp;&emsp;图像识别有时也可称为图像识别，主要是对图像中感兴趣的目标进行检测，从而获取它们的客观信息并同时建立对图像的描述。图像识别的主要过程如图1所示：

<center>![图像识别的主要过程]({{'/styles/images/image recognition/图1.jpg' | prepend: site.baseurl }})</center>

## 1. 特征提取

&emsp;&emsp;特征提取是从原始数据中提取各类特征并变换成为更有利于处理的属性空间，然后对其进行融合、辨识、分类等各种处理，从而为目标检测和识别服务。  
&emsp;&emsp;特征提取常常分几步进行：（1）特征形成。根据被识别的对象产生一组原始特征，它们可以是传感器的直接测量值，也可以是将传感器的测量值作某些计算后得到的值。（2）特征选择。由特征形成过程得到的原始特征可能很多，如果把所有的原始特征都作为分类特征送往分类器，不仅使得分类器复杂，分类计算判别量大，而且分类错误概率也不一定小，因此需要减少特征维数。特征选择就是从众多不同特征度量值的集合中, 按某一准则(挑出一些最有效的特征) 选出供分类用的子集, 作为降维的分类特征。（3）特征提取。特征提取是另一种减少特征维数的方法，它是使生成的众多特征度量值通过某种数学变换产生为较少的特征度量值，即通过映射(或变换) 的方法把高维的特征向量变换为低维的特征向量。它们的目的都是为了在尽可能保留识别信息的前提下，降低特征空间的维数，以达到有效分类。

### 1.1	原始特征提取

- **基于颜色特征**  
a)	颜色直方图  
b)	颜色集，是对颜色直方图的一种近似，其将图像表达为一个二进制的颜色索引集  
c)	颜色矩，其将图像中任何的颜色分布用它的矩来表示  
d)	颜色聚合向量  
e)	颜色相关图  

&emsp;&emsp;颜色特征是一种全局特征，描述了图像或图像区域所对应的景物的表面性质。由于颜色对图像或图像区域的方向、大小等变化不敏感，所以颜色特征不能很好的捕捉图像中对象的局部特征。另外，仅使用颜色特征查询时，如果数据库很大，常会将许多不需要的图像也检索出来。颜色直方图是最常用的表达颜色特征的方法，其优点是不受图像旋转和平移变化的影响，进一步借助归一化还可不受图像尺度变化的影响，基缺点是没有表达出颜色空间分布的信息。 
 
- **基于纹理特征**  
a)	基于统计的灰度共生矩阵和能量谱函数法  
b)	几何法，例如基于图像基元的结构化方法  
c)	模型法，以图像的构造模型为基础，采用模型参数作为纹理特征，典型的方法有随机场模型法  
d)	信号处理法，例如，小波变换  

&emsp;&emsp;纹理特征也是一种全局特征，它也描述了图像或图像区域所对应景物的表面性质。作为一种统计特征，纹理特征常具有旋转不变性，并且对于噪声有较强的抵抗能力。但纹理只是一种物体表面的特性，无法完全反映出物体的本质属性，所以仅利用纹理特征无法获得高层次图像内容，且纹理特征还有一个很明显的缺点是当图像的分辨率变化的时候，所计算出来的纹理可能会有较大偏差。  

- **基于形状特征**  
a)	基于边界的，例如Hough变换，傅里叶变换等  
b)	基于区域的，例如矩不变量，几何矩特征，转动惯量等  
c)	其他方法，例如有限元法，旋转函数和小波描述符等  

&emsp;&emsp;基于形状特征的检索方法都可以比较有效地利用图像中感兴趣的目标来进行检索 ，但也存在一些问题，例如当目标有变形时检索结果就不太可靠，且许多形状特征仅描述了目标的局部特征，对全面描述目标有较高的时间和空间要求等。 
 
- **基于空间关系特征**  

&emsp;&emsp;空间关系，是指图像中分割出来的多个目标之间的相互的空间位置或相对方向关系，这些关系可分为连接/邻接关系、交叠/重叠关系和包含/包容关系等。提取图像空间关系特征可以有两种方法：一种方法是首先对图像进行自动分割，划分出图像中所包含的对象或颜色区域，然后根据这些区域提取图像特征，并建立索引；另一种方法则简单地将图像均匀地划分为若干规则子块，然后对每个图像子块提取特征，并建立索引。  
&emsp;&emsp;空间关系特征的使用可加强对图像内容的描述区分能力，但空间关系特征常对图像或目标的旋转、反转、尺度变化等比较敏感。另外，实际应用中，仅仅利用空间信息往往是不够的，不能有效准确地表达场景信息。  

### 1.2	特征变换

- **主成分分析法**  

&emsp;&emsp;PCA方法是从一组特征中通过求解最优的正交变换，得到一组相互间方差最大的新特征，它们是原始特征的线性组合，且相互之间是不相关的，再对新特征进行重要性排序，选取前几个主成分。用较少的主成分来表示数据，可以实现特征的降维，还可以消除数据中的噪声。该算法不考虑样本的类别信息，是一种无监督的方法。  

- **线性判别方法**  

&emsp;&emsp;该方法基本思想是将高维的数据样本投影到最佳判别的矢量空间，以达到提取分类信息和压缩特征空间维数的效果，投影后保证数据样本在新的子空间类间距离最大和类内距离最小，即样本数据在该空间中有最佳的可分离性。Fisher线性判别分析是最具有代表性的LDA 法。 

- **多维尺度法**  

&emsp;&emsp;MDS是一种很经典的数据映射方法，其根据样本之间的距离关系或不相似度关系在低维空间里生成对样本的一种表示。MDS分为度量型和非度量型两种，度量型MDS把样本间的距离关系或不相似度关系看作一种定量的度量，尽可能的在低维空间里保持这种度量关系；非度量型MDS把样本间的距离关系或不相似度关系看作一种定性的关系，在低维空间里只需保持这种关系的顺序。 
 
- **核主成分分析法**  

&emsp;&emsp;该方法对样本进行非线性变换，通过在变换空间进行主成分分析来实现在原空间的非线性主成分分析。根据可再生希尔伯特空间的性质，在变换空间中的协方差矩阵可以通过原空间中的核函数进行运算，从而绕过复杂的非线性变换。核方法对于不同的问题选择合适的核函数类型，不同的核函数类型反映了对数据分布的不同假设，也可以看作是对数据引入了一种非线性距离度量。

- **基于流型学习的方法**  

&emsp;&emsp;其基本思想是通过局部距离来定义非线性距离度量，在样本分布较密集的情况下可以实现各种复杂的非线性距离度量。具体方法有：  
&emsp;&emsp;a)	等容特征映射（IsoMap）--欧氏距离累加  
&emsp;&emsp;b)	局部线性嵌入（LLE）--近邻样本线性重构  
&emsp;&emsp;c)	拉普拉斯特征映射（LE）--邻域选取和样本间相似度表达  

### 1.3	特征选择

&emsp;&emsp;特诊选择的过程为：从特征全集中产生出一个特征子集，然后用评价函数对该特征子集进行评价，评价的结果与停止准则进行比较，若评价结果比停止准则好就停止，否则就继续产生下一组特征子集，继续进行特征选择。选出来的特征子集一般还要验证其有效性。综上所述，特征选择过程一般包括产生过程，评价函数，停止准则，验证过程，这4个部分。  
&emsp;&emsp;a)	产生过程(Generation Procedure ):产生过程是搜索特征子集的过程，负责为评价函数提供特征子集。  
&emsp;&emsp;b)	评价函数(Evaluation Function ):评价函数是评价一个特征子集好坏程度的一个准则。   
&emsp;&emsp;c)	停止准则(Stopping Criterion ):停止准则是与评价函数相关的，一般是一个阈值，当评价函数值达到这个阈值后就可停止搜索。  
&emsp;&emsp;d)	验证过程(Validation Procedure ):在验证数据集上验证选出来的特征子集的有效性。  

![特征选择的过程( M.Dash and H. Liu 1997 )]({{'/styles/images/image recognition/图2.jpg' | prepend: site.baseurl }})

#### 1.3.1 产生过程

&emsp;&emsp;产生过程是搜索特征子空间的过程。搜索的算法分为完全搜索(Complete)，启发式搜索(Heuristic)，随机搜索(Random)3大类。  

![产生过程算法分类( M.Dash and H. Liu 1997 )]({{'/styles/images/image recognition/图3.jpg' | prepend: site.baseurl }})

- **完全搜索**  

&emsp;&emsp;完全搜索分为穷举搜索(Exhaustive)与非穷举搜索(Non-Exhaustive)两类。  
&emsp;&emsp;1)  广度优先搜索(Breadth First Search )  
&emsp;&emsp;算法描述：广度优先遍历特征子空间。  
&emsp;&emsp;算法评价：枚举了所有的特征组合，属于穷举搜索，时间复杂度是O(2n)，实用性不高。  
&emsp;&emsp;2)	分支限界搜索(Branch and Bound )  
&emsp;&emsp;算法描述：在穷举搜索的基础上加入分支限界。例如：若断定某些分支不可能搜索出比当前找到的最优解更优的解，则可以剪掉这些分支。  
&emsp;&emsp;3)	定向搜索(Beam Search )  
&emsp;&emsp;算法描述：首先选择N个得分最高的特征作为特征子集，将其加入一个限制最大长度的优先队列，每次从队列中取出得分最高的子集，然后穷举向该子集加入1个特征后产生的所有特征集，将这些特征集加入队列。  
&emsp;&emsp;4)	最优优先搜索( Best First Search )  
&emsp;&emsp;算法描述：与定向搜索类似，唯一的不同点是不限制优先队列的长度。  

- **启发式搜索**  

&emsp;&emsp;1)	序列前向选择(SFS , Sequential Forward Selection )  
&emsp;&emsp;算法描述：特征子集X从空集开始，每次选择一个特征x加入特征子集X，使得特征函数J( X)最优。简单说就是，每次都选择一个使得评价函数的取值达到最优的特征加入，其实就是一种简单的贪心算法。  
&emsp;&emsp;算法评价：缺点是只能加入特征而不能去除特征。例如：特征A完全依赖于特征B与C，可以认为如果加入了特征B与C则A就是多余的。假设序列前向选择算法首先将A加入特征集，然后又将B与C加入，那么特征子集中就包含了多余的特征A。  
&emsp;&emsp;2)	序列后向选择(SBS , Sequential Backward Selection )  
&emsp;&emsp;算法描述：从特征全集O开始，每次从特征集O中剔除一个特征x，使得剔除特征x后评价函数值达到最优。  
&emsp;&emsp;算法评价：序列后向选择与序列前向选择正好相反，它的缺点是特征只能去除不能加入。   
另外，SFS与SBS都属于贪心算法，容易陷入局部最优值。  
&emsp;&emsp;3)	双向搜索(BDS , Bidirectional Search )  
&emsp;&emsp;算法描述：使用序列前向选择(SFS)从空集开始，同时使用序列后向选择(SBS)从全集开始搜索，当两者搜索到一个相同的特征子集C时停止搜索。
双向搜索的出发点是$2N^{k/2}<N^k$。如下图所示，O点代表搜索起点，A点代表搜索目标。灰色的圆代表单向搜索可能的搜索范围，绿色的2个圆表示某次双向搜索的搜索范围，容易证明绿色的面积必定要比灰色的要小。  

![双向搜索]({{'/styles/images/image recognition/图4.jpg' | prepend: site.baseurl }})

&emsp;&emsp;4)	增L去R选择算法( LRS , Plus-L Minus-R Selection )  
&emsp;&emsp;该算法有两种形式:  
&emsp;&emsp;<1> 算法从空集开始，每轮先加入L个特征，然后从中去除R个特征，使得评价函数值最优，( L> R )  
&emsp;&emsp;<2> 算法从全集开始，每轮先去除R个特征，然后加入L个特征，使得评价函数值最优，( L< R )  
&emsp;&emsp;算法评价：增L去R选择算法结合了序列前向选择与序列后向选择思想， L与R的选择是算法的关键。  
&emsp;&emsp;5)	序列浮动选择(Sequential Floating Selection )  
　　算法描述：序列浮动选择由增L去R选择算法发展而来，该算法与增L去R选择算法的不同之处在于：序列浮动选择的L与R不是固定的，而是“浮动”的，也就是会变化的。  
&emsp;&emsp;序列浮动选择根据搜索方向的不同，有以下两种变种。  
&emsp;&emsp;<1>序列浮动前向选择(SFFS , Sequential Floating Forward Selection )  
算法描述：从空集开始，每轮在未选择的特征中选择一个子集x，使加入子集x后评价函数达到最优，然后在已选择的特征中选择子集z，使剔除子集z后评价函数达到最优。  
&emsp;&emsp;<2>序列浮动后向选择(SFBS , Sequential Floating Backward Selection )  
&emsp;&emsp;算法描述：与SFFS类似，不同之处在于SFBS是从全集开始，每轮先剔除特征，然后加入特征。  
&emsp;&emsp;算法评价：序列浮动选择结合了序列前向选择、序列后向选择、增L去R选择的特点，并弥补了它们的缺点。  
&emsp;&emsp;6)	决策树(Decision Tree Method , DTM)  
&emsp;&emsp;算法描述：在训练样本集上运行C4.5或其他决策树生成算法，待决策树充分生长后，再在树上运行剪枝算法。则最终决策树各分支处的特征就是选出来的特征子集了。决策树方法一般使用信息增益作为评价函数。 
  
- **随机算法** 
 
&emsp;&emsp;1)	随机产生序列选择算法(RGSS, Random Generation plus SequentialSelection)  
&emsp;&emsp;算法描述：随机产生一个特征子集，然后在该子集上执行SFS与SBS算法。  
&emsp;&emsp;算法评价：可作为SFS与SBS的补充，用于跳出局部最优值。  
&emsp;&emsp;2)	模拟退火算法(SA, Simulated Annealing )  
&emsp;&emsp;模拟退火算法可参考：大白话解析模拟退火算法 。   
&emsp;&emsp;算法评价：模拟退火一定程度克服了序列搜索算法容易陷入局部最优值的缺点，但是若最优解的区域太小（如所谓的“高尔夫球洞”地形），则模拟退火难以求解。  
&emsp;&emsp;3)	遗传算法(GA,  Genetic Algorithms )    
&emsp;&emsp;遗传算法可参考：遗传算法入门 。  
&emsp;&emsp;算法描述：首先随机产生一批特征子集，并用评价函数给这些特征子集评分，然后通过交叉、突变等操作繁殖出下一代的特征子集，并且评分越高的特征子集被选中参加繁殖的概率越高。这样经过N代的繁殖和优胜劣汰后，种群中就可能产生了评价函数值最高的特征子集。  
&emsp;&emsp;随机算法的共同缺点：依赖于随机因素，有实验结果难以重现。  

#### 1.3.2 评价函数

&emsp;&emsp;评价函数的作用是评价产生过程所提供的特征子集的好坏。评价函数根据其工作原理，主要分为筛选器(Filter)、封装器( Wrapper )和嵌入式( Embedded )三大类。筛选器通过分析特征子集内部的特点来衡量其好坏。筛选器一般用作预处理，与分类器的选择无关。筛选器的原理如下图5所示。  

![Filter原理(Ricardo Gutierrez-Osuna 2008 )]({{'/styles/images/image recognition/图5.jpg' | prepend: site.baseurl }})

&emsp;&emsp;封装器实质上是一个分类器，封装器用选取的特征子集对样本集进行分类，分类的精度作为衡量特征子集好坏的标准。封装器的原理如图6所示。  

![Wrapper原理(Ricardo Gutierrez-Osuna 2008 )]({{'/styles/images/image recognition/图6.jpg' | prepend: site.baseurl }})

&emsp;&emsp;下面简单介绍常见的评价函数。  

- **Filter方式**
  
&emsp;&emsp;Filter式的特征选择方法一般使用评价准则来使特征与类别间的相关性最大，特征间的相关性最小。该方式可以很快的排除掉很多不相关的噪声特征，缩小优化特征子集搜索的规模，计算效率高，通用性好，可用作特征的预筛选器。但当特征和分类器息息相关时，该方法不能保证选择出一个优化特征子集，即使能找到一个满足条件的优化子集，其计算规模也比较大。根据评价函数可分为四类：  
&emsp;&emsp;1)	基于距离度量的  
&emsp;&emsp;常用的距离度量有：欧氏距离，Minkowski距离，Chebychev距离和平方距离等。Relief及其扩展算法ReliefF和RRelidfF，分支定界法和BFF算法都是基于距离度量的特征选择算法。  
&emsp;&emsp;2)	基于信息度量的  
&emsp;&emsp;常用信息度量：信息增益与互信息，信息增益：可以有效的选出关键特征，剔除无关特征；互信息：描述两个随机变量之间相互依存关系的强弱，常见算法如下：  
&emsp;&emsp;a)	基于互信息的MIFS算法  
&emsp;&emsp;b)	基于最小冗余最大相关（mRMR）的方法  
&emsp;&emsp;c)	基于互信息的快速滤波算法FCBF  
&emsp;&emsp;d)	基于条件互信息的CMIM算法   
&emsp;&emsp;e)	基于动态互信息的特征选择算法  
&emsp;&emsp;由于信息熵理论不要求假定数据分布是已知的能够以量化的形式度量特征间的不确定程度，且能有效地度量特征间的非线性关系，基于信息度量的特征选择算法成为近年来研究的热点，提出了许多基于信息理论的改进算法。  
&emsp;&emsp;3)	基于依赖性度量的  
&emsp;&emsp;该方法利用一些统计相关系数，如Pearson相关系数，Fisher得分，方差得分，t检验，秩和检验或Hilbert-Schmidt依赖性准则等来度量特征相对于类别可分离性间的重要性程度。有人提出了一种基于稀疏表示的特征选择方法，且在人脸图像聚类实验中取得了较好的结果。  
&emsp;&emsp;4)	基于一致性度量的  
&emsp;&emsp;该方法其思想是寻找全集有相同区分能力的最小子集，尽可能保留原始特征的辨识能力。它具有单调、快速、去除冗余和不相关特征、处理噪声等优点，但其对噪声数据敏感，且只适合处理离散特征。典型的算法有Focus，LVF等。
  
- **Wrapper方式**  

&emsp;&emsp;Wrapper方式依据选择子集最终被用于构造分类模型，把特征选择算法作为学习算法的一个组成部分，直接使用训练结果的准确率作为特征重要性程度的评价标准。该方法在速度上要比Filter方式慢，但它所选的优化特征子集规模相对要小的多，非常有利于关键特征的辨识；同时其准确率比较高，但泛化能力较差，时间复杂度较高。  
&emsp;&emsp;目前，关于Wrapper方式的研究也比较多，例如：  
&emsp;&emsp;1)	Hsu等人用决策树来进行特征选择，采用遗传算法来寻找使得决策树分类错误率最小的一组特征子集  
&emsp;&emsp;2)	Chiang等人将Fisher判别分析与遗传算法结合，用于化工故障过程中辨识关键变量，其效果也不错。  
&emsp;&emsp;3)	Guyon等人利用支持向量机的分类性能衡量特征的重要性，最终构造了一个分类性能较高的分类器。   
&emsp;&emsp;4)	Krzysztof提出了一种基于相互关系的双重策略的Wrapper特征选择方法FFSR(fast feature subset ranking)，以特征子集作为评价单位，以子集收敛能力作为评价标准  
&emsp;&emsp;5)	戴平等人提出了一种基于SVM的快速特征选择方法   
 
- **Embedded方式**   

&emsp;&emsp;针对Filter和Wrapper方式的利弊，提出了Embedded方式的特征选择方法，该方式先用filter方法初步去掉无关或噪声特征，只保留少量特征，减少后续搜索规模，然后再用Wrapper方法进一步优化，选择分类准确率最高的特征子集。例如，Li G-Z等人先使用互信息度量标准和随机重采样技术获取前k个重要特征，再使用SVM构造分类器。  

#### 1.3.3 停止准则

#### 1.3.4 验证过程

## 2. 分类器的训练和使用

&emsp;&emsp;目前，基于图像的目标识别技术的理论和方法主要有经典的统计目标识别、基于不变量的目标识别、基于知识的目标识别和基于人工神经网络的目标识别四种。  

### 2.1 基于统计的目标识别

&emsp;&emsp;统计图像识别算法最初源于统计模式识别，统计决策和估计理论是这类算法的基础。目标特征和参考目标模式特征的获取过程都不可避免地引入了噪声和各种不确定因素，所以需要将统计方法和决策理论应用到目标识别算法，即统计分类器，分类的基础是可被传感器所测量的特征。目前主要使用的统计图像识别方法有两类: 基于似然函数的模式分类方法, 主要有Bayes 判决准则、Fisher 判决准则等。另一类是基于距离函数的模式分类方法, 是一种集群分析技术。该方法应用并不广泛。

### 2.2 基于不变量的目标识别

&emsp;&emsp;基于不变量的目标识别就是在目标特征中提取满足尽可能多条件下的不变量，作为目标的本质属性，并以此作为分类识别的特征度量。这是因为目标所处的场景常常很复杂，对于运动目标，成像的视点和条件也不断地发生变化，以及目标本身可能发生的姿态变换、缺损、模糊和遮挡，使得图像识别是一个非常复杂的过程。要准确地识别图像中的目标，需要提取目标特征在不同条件下都保持不变的量，这个不变量体现了目标特征的本质属性。关于对不变量的寻找，一直是图像识别研究领域内的一个热点问题，最具代表性的是目标轮廓特征的矩不变量，还有具有旋转、平移和尺度不变性的傅立叶描述子、su yang 统计矩阵描述子以及基于动态小波变换的具有仿射不变性的轮廓不变量等等。但是这些不变量一般也只是满足复杂实际情况的某些条件，但这种方法在目标识别中得到广泛的应用，并取得了不错的效果。

### 2.3 基于知识的目标识别

&emsp;&emsp;基于知识的图像识别是对目标和场景赋予正确的知识表达，是从机器智能的角度理解图像的基础，有利于从复杂背景中检测、识别目标。这些知识是在识别之前，对目标所处的环境特点和待识别目标的特征进行预先研究获取的。对这些先验信息（知识）建立知识库，在建立了正确的知识库的前提下，分析含有目标的图像，利用先验知识检测和识别目标。例如红外图像中对桥梁的识别我们可以有如下先验知识：（1）桥梁的象素灰度值适中；（2）平行邻域为水域；（3）垂直邻域为陆域；（4）沿桥梁方向桥梁象素点形成线状聚集。同样可以描述出水域和陆域的先验信息，然后对图像进行分析后，综合这些先验知识实现桥梁在图像中的位置。

### 2.4 基于人工神经网络的目标识别

&emsp;&emsp;基于人工神经网络的图像识别方法是模仿人眼视觉功能与生物、医学相关的一种仿生方法。人工神经网络具有信息分布式存储、大规模自适应并行处理、高度的容错性等优点, 是应用于图像识别的基础, 特别是学习能力和容错性对不确定的图像识别具有独到之处。神经网络的并行结构决定了它对输入模式信息的不完备或特征的缺损不敏感。这是一种智能化的模式识别系统, 具有很强的发展应用前景。